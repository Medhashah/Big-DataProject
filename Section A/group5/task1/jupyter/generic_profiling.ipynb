{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "from collections import Counter\n",
    "from pyspark import SparkContext, RDD\n",
    "from csv import reader\n",
    "import itertools\n",
    "import rdd_util\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"project\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql import functions as F\n",
    "from collections import Counter\n",
    "from pyspark import SparkContext, RDD\n",
    "from csv import reader\n",
    "import itertools\n",
    "\n",
    "from dateutil import parser\n",
    "\n",
    "def is_date(s: str, col: str):\n",
    "    col_name = col.lower()\n",
    "    if 'date' in col_name or 'year' in col_name \\\n",
    "            or 'time' in col_name or 'month' in col_name \\\n",
    "            or 'day' in col_name:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def mapd(x: List):\n",
    "    \"\"\"\n",
    "    TODO: check date type\n",
    "    :param x:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # [col_idx, (value, type)]\n",
    "    res = (x[0], [x[1], None])\n",
    "    if (x[1] == ''):\n",
    "        res[1][1] = 'empty'\n",
    "    elif(is_date(x[1],x[0])):\n",
    "        res[1][1] = 'date'\n",
    "    elif (is_int(x[1])):\n",
    "        res[1][1] = 'int'\n",
    "        res[1][0] = int(res[1][0])\n",
    "    elif (is_float(x[1])):\n",
    "        res[1][1] = 'real'\n",
    "        res[1][0] = float(res[1][0])\n",
    "    else:\n",
    "        res[1][1] = 'text'\n",
    "    return res\n",
    "\n",
    "\n",
    "def is_int(s: str):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_float(value: str):\n",
    "    if '.' not in value:\n",
    "        return False\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def generate_meta(spark: SparkSession, path: str):\n",
    "    # read dataframe\n",
    "    sc = SparkContext.getOrCreate()\n",
    "    # Add index to each row, [([...], 0),([...], 1)...]\n",
    "    rdd = sc.textFile(path, 1).mapPartitions(lambda x: reader(x, delimiter='\\t')).zipWithIndex()\n",
    "    header = rdd.filter(lambda x: x[1] == 0) \\\n",
    "        .map(lambda x: (x[0])).collect()[0]  # extract the first part, ignore idx\n",
    "    rows = rdd.filter(lambda x: x[1] != 0).map(lambda x: x[0])\n",
    "    file_name = path.split('/')[-1]\n",
    "    metadata = {\n",
    "        'dataset_name': file_name,\n",
    "        'key_column_candidates': header\n",
    "    }\n",
    "    N = len(header)\n",
    "    # Transform to [(col_idx, value),(col_idx, value)...]\n",
    "    items = rows.flatMap(\n",
    "        lambda x, h=header: [(h[i], x[i]) for i in range(N)])\n",
    "\n",
    "    # Transform to [(col_idx, (value, type)),(col_idx, (value, type))...]\n",
    "    mapped_items = items.map(mapd)\n",
    "    col_map = {}\n",
    "    for col in header:\n",
    "        col_map[col] = {}\n",
    "\n",
    "    res2 = generate_distinct_top5(items)\n",
    "    res1 = generate_null_empty(mapped_items)\n",
    "    # [(col,non-empty, empty, total, distinct_num, top5:(col_name,freq))]\n",
    "    flat_res = res1.join(res2).map(lambda x: (x[0], (*x[1][0], *x[1][1]))).collect()\n",
    "    columns = []\n",
    "    for res in flat_res:\n",
    "        column_data = {\n",
    "            'column_name': res[0],\n",
    "            'number_non_empty_cells': res[1][0],\n",
    "            'number_empty_cells': res[1][1],\n",
    "            'number_distinct_values': res[1][3],\n",
    "            'frequent_values': [x[0] for x in res[1][4]]\n",
    "        }\n",
    "        columns.append(column_data)\n",
    "    metadata['columns'] =columns\n",
    "    return metadata\n",
    "\n",
    "\n",
    "\n",
    "def generate_null_empty(mapped_items: RDD) -> RDD:\n",
    "    \"\"\"\n",
    "    :param mapped_items: [(col,(value, type)), ...]\n",
    "    :return: [(col1,[non-empty, empty, total]), (col2,[null-empty, empty, total])]\n",
    "    \"\"\"\n",
    "\n",
    "    def seqFunc(local, x):\n",
    "        res = [i for i in local];\n",
    "        if (x[1] != 'empty'):\n",
    "            res[0] = local[0] + 1\n",
    "        else:\n",
    "            res[1] = local[1] + 1\n",
    "        res[2] = local[2] + 1\n",
    "        return res\n",
    "\n",
    "    combFunc = (lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    "    count = mapped_items.aggregateByKey((0, 0, 0), seqFunc, combFunc)\n",
    "    return count\n",
    "\n",
    "\n",
    "def generate_distinct_top5(items: RDD) -> RDD:\n",
    "    \"\"\"\n",
    "    :param items: [(col,value),...]\n",
    "    :return: [(col,(distinct_num, [top5...])),(col,(distinct_num, [top5...])),...]\n",
    "    \"\"\"\n",
    "    freq_items = items.map(lambda x: ((x[0], x[1]), 1)) \\\n",
    "        .aggregateByKey((0, 0),\n",
    "                        (lambda x, y: (0, x[1] + 1)),\n",
    "                        (lambda x, y: (x[1] + y[1]))) \\\n",
    "        .map(lambda x: ((x[0][0]), (x[0][1], x[1][1])))\n",
    "    sorted_grouped_freq_items = freq_items.sortBy(lambda x: x[1][1], ascending=False).groupByKey()\n",
    "    res = sorted_grouped_freq_items.mapValues(lambda x: (len(x), list(itertools.islice(x, 5))))\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/user/hm74/NYCOpenData/2bmr-jdsv.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19 ms, sys: 4 ms, total: 23 ms\n",
      "Wall time: 2.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read dataframe\n",
    "sc = SparkContext.getOrCreate()\n",
    "# Add index to each row, [([...], 0),([...], 1)...]\n",
    "rdd = sc.textFile(path, 10).mapPartitions(lambda x: reader(x, delimiter='\\t')).zipWithIndex()\n",
    "header = rdd.filter(lambda x: x[1] == 0) \\\n",
    "    .map(lambda x: (x[0])).collect()[0]  # extract the first part, ignore idx\n",
    "rows = rdd.filter(lambda x: x[1] != 0).map(lambda x: x[0])\n",
    "file_name = path.split('/')[-1]\n",
    "metadata = {\n",
    "    'dataset_name': file_name,\n",
    "    'key_column_candidates': header\n",
    "}\n",
    "N = len(header)\n",
    "# Transform to [(col_idx, value),(col_idx, value)...]\n",
    "items = rows.flatMap(\n",
    "    lambda x, h=header: [(h[i], x[i]) for i in range(N)])\n",
    "\n",
    "# Transform to [(col_idx, (value, type)),(col_idx, (value, type))...]\n",
    "mapped_items = items.map(mapd).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Base_Number', ['B02756', 'text']),\n",
       " ('Wave_Number', [3, 'int']),\n",
       " ('Base_Name', ['ALLY CAR SERVICE LLC', 'text']),\n",
       " ('DBA', ['ACTIVE EXPRESS CAR & LIMO 2', 'text']),\n",
       " ('years', ['2015', 'date']),\n",
       " ('Week_Number', [40, 'int']),\n",
       " ('Pickup_Start_Date', ['09/27/2015 12:00:00 AM', 'date']),\n",
       " ('Pickup_End_Date', ['10/03/2015 12:00:00 AM', 'date']),\n",
       " ('Total_Dispatched_Trips', [19, 'int']),\n",
       " ('Unique_Dispatched_Vehicle', [6, 'int'])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_items.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped_items.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "res2 = generate_distinct_top5(items)\n",
    "res1 = generate_null_empty(mapped_items)\n",
    "%%time\n",
    "res1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Base_Number', ['B02756', 'text']),\n",
       " ('Wave_Number', [3, 'int']),\n",
       " ('Base_Name', ['ALLY CAR SERVICE LLC', 'text']),\n",
       " ('DBA', ['ACTIVE EXPRESS CAR & LIMO 2', 'text']),\n",
       " ('years', ['2015', 'date']),\n",
       " ('Week_Number', [40, 'int']),\n",
       " ('Pickup_Start_Date', ['09/27/2015 12:00:00 AM', 'date']),\n",
       " ('Pickup_End_Date', ['10/03/2015 12:00:00 AM', 'date']),\n",
       " ('Total_Dispatched_Trips', [19, 'int']),\n",
       " ('Unique_Dispatched_Vehicle', [6, 'int']),\n",
       " ('Base_Number', ['B02756', 'text']),\n",
       " ('Wave_Number', [3, 'int']),\n",
       " ('Base_Name', ['ALLY CAR SERVICE LLC', 'text']),\n",
       " ('DBA', ['ACTIVE EXPRESS CAR & LIMO 2', 'text']),\n",
       " ('years', ['2015', 'date']),\n",
       " ('Week_Number', [41, 'int']),\n",
       " ('Pickup_Start_Date', ['10/04/2015 12:00:00 AM', 'date']),\n",
       " ('Pickup_End_Date', ['10/10/2015 12:00:00 AM', 'date']),\n",
       " ('Total_Dispatched_Trips', [58, 'int']),\n",
       " ('Unique_Dispatched_Vehicle', [8, 'int'])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_items.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_type_items = mapped_items.map(lambda x: ((x[0],x[1][1]),x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Base_Number', 'text'), 'B02756'),\n",
       " (('Wave_Number', 'int'), 3),\n",
       " (('Base_Name', 'text'), 'ALLY CAR SERVICE LLC'),\n",
       " (('DBA', 'text'), 'ACTIVE EXPRESS CAR & LIMO 2'),\n",
       " (('years', 'date'), '2015'),\n",
       " (('Week_Number', 'int'), 40),\n",
       " (('Pickup_Start_Date', 'date'), '09/27/2015 12:00:00 AM'),\n",
       " (('Pickup_End_Date', 'date'), '10/03/2015 12:00:00 AM'),\n",
       " (('Total_Dispatched_Trips', 'int'), 19),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), 6)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_type_items.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num_type_items = col_type_items.filter(lambda x: x[0][1]=='int'or x[0][1]=='real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Wave_Number', 'int'), 3),\n",
       " (('Week_Number', 'int'), 40),\n",
       " (('Total_Dispatched_Trips', 'int'), 19),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), 6),\n",
       " (('Wave_Number', 'int'), 3),\n",
       " (('Week_Number', 'int'), 41),\n",
       " (('Total_Dispatched_Trips', 'int'), 58),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), 8),\n",
       " (('Wave_Number', 'int'), 3),\n",
       " (('Week_Number', 'int'), 42)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_num_type_items.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seqFunc(local, x):\n",
    "    max_value = x if x>local[0] else local[0]\n",
    "    min_value = x if x<local[1] else local[1]    \n",
    "    return (max_value,min_value,local[2]+x, local[3]+1)\n",
    "\n",
    "combFunc = (lambda x, y: (max(x[0],y[0]), min(x[1], y[1]), x[2] + y[2], x[3] + y[3]))\n",
    "num_statistic = col_num_type_items.aggregateByKey((0,0,0,0),seqFunc, combFunc)\n",
    "num_statistic = num_statistic.map(lambda x: (x[0],[*x[1],x[1][2]/x[1][3]]))\n",
    "# [(('col_name', 'num_type'),(value, mean))...]\n",
    "col_num_mean_items =col_num_type_items.join(num_statistic.map(lambda x: (x[0],x[1][4])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 ms, sys: 1e+03 µs, total: 8 ms\n",
      "Wall time: 1.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('Wave_Number', 'int'), [4, 0, 272219, 101033, 2.6943572892025376]),\n",
       " (('Week_Number', 'int'), [53, 0, 2628258, 101033, 26.013856858650144]),\n",
       " (('Total_Dispatched_Trips', 'int'),\n",
       "  [909056, 0, 549722961, 101033, 5441.0238337968785]),\n",
       " (('Unique_Dispatched_Vehicle', 'int'),\n",
       "  [33578, 0, 16209232, 101033, 160.43502617956509])]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "num_statistic.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Unique_Dispatched_Vehicle', 'int'), (6, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (8, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (8, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (7, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (10, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (3, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (3, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (3, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (3, 160.43502617956509)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'), (3, 160.43502617956509))]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_num_mean_items.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "result_dev= col_num_mean_items.aggregateByKey((0,), lambda local, x:(local[0]+(x[0]-x[1])**2,) , (lambda x, y: (x[0] + y[0])))\n",
    "result_std = result_dev.map(lambda x:(x[0],math.sqrt(x[1][0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Unique_Dispatched_Vehicle', 'int'), (113773130619.74493,)),\n",
       " (('Wave_Number', 'int'), (77431.75309055187,)),\n",
       " (('Week_Number', 'int'), (22346320.600396164,)),\n",
       " (('Total_Dispatched_Trips', 'int'), (93374491035552.31,))]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dev.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Unique_Dispatched_Vehicle', 'int'), 337302.72844989697),\n",
       " (('Wave_Number', 'int'), 278.26561607671164),\n",
       " (('Week_Number', 'int'), 4727.1895033303),\n",
       " (('Total_Dispatched_Trips', 'int'), 9663047.709473047)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_std.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Wave_Number', 'int'),\n",
       "  ([4, 0, 272219, 101033, 2.6943572892025376], 278.26561607671164)),\n",
       " (('Unique_Dispatched_Vehicle', 'int'),\n",
       "  ([33578, 0, 16209232, 101033, 160.43502617956509], 337302.72844989697)),\n",
       " (('Week_Number', 'int'),\n",
       "  ([53, 0, 2628258, 101033, 26.013856858650144], 4727.1895033303)),\n",
       " (('Total_Dispatched_Trips', 'int'),\n",
       "  ([909056, 0, 549722961, 101033, 5441.0238337968785], 9663047.709473047))]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_statistic.join(result_std).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Wave_Number', 'int'),\n",
       "  [4, 0, 272219, 101033, 2.6943572892025376, 278.26561607671164]],\n",
       " [('Unique_Dispatched_Vehicle', 'int'),\n",
       "  [33578, 0, 16209232, 101033, 160.43502617956509, 337302.72844989697]],\n",
       " [('Week_Number', 'int'),\n",
       "  [53, 0, 2628258, 101033, 26.013856858650144, 4727.1895033303]],\n",
       " [('Total_Dispatched_Trips', 'int'),\n",
       "  [909056, 0, 549722961, 101033, 5441.0238337968785, 9663047.709473047]]]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_statistic.join(result_std).map(lambda x: [x[0],[*x[1][0],x[1][1]]]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_num_statistic(col_num_type_items: RDD) -> RDD:\n",
    "    \"\"\"\n",
    "    :param col_num_type_items: [(('Wave_Number', 'int'), 3),(('Week_Number', 'int'), 40)...]\n",
    "    :return: ['Wave_Number', 'int'], [max_value, min_value, sum, count, mean, std])\n",
    "    \"\"\"\n",
    "\n",
    "    def seqFunc(local, x):\n",
    "        max_value = x if x > local[0] else local[0]\n",
    "        min_value = x if x < local[1] else local[1]\n",
    "        return (max_value, min_value, local[2] + x, local[3] + 1)\n",
    "\n",
    "    combFunc = (lambda x, y: (max(x[0], y[0]), min(x[1], y[1]), x[2] + y[2], x[3] + y[3]))\n",
    "    num_statistic = col_num_type_items.aggregateByKey((0, 0, 0, 0), seqFunc, combFunc)\n",
    "    num_statistic = num_statistic.map(lambda x: (x[0], [*x[1], x[1][2] / x[1][3]]))\n",
    "    # [(('col_name', 'num_type'),(value, mean))...]\n",
    "    col_num_mean_items = col_num_type_items.join(num_statistic.map(lambda x: (x[0], x[1][4])))\n",
    "    result_dev = col_num_mean_items.aggregateByKey((0,), lambda local, x: (local[0] + (x[0] - x[1]) ** 2,), (lambda x, y: (x[0] + y[0])))\n",
    "    result_std = result_dev.map(lambda x: (x[0], math.sqrt(x[1][0])))\n",
    "    return num_statistic.join(result_std).map(lambda x: [x[0],[*x[1][0],x[1][1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40 ms, sys: 8 ms, total: 48 ms\n",
      "Wall time: 3.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res= generate_num_statistic(col_num_type_items)\n",
    "res.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Wave_Number', 'int'),\n",
       "  [4, 0, 272219, 101033, 2.6943572892025376, 278.26561607671164]],\n",
       " [('Unique_Dispatched_Vehicle', 'int'),\n",
       "  [33578, 0, 16209232, 101033, 160.43502617956509, 337302.72844989697]],\n",
       " [('Week_Number', 'int'),\n",
       "  [53, 0, 2628258, 101033, 26.013856858650144, 4727.1895033303]],\n",
       " [('Total_Dispatched_Trips', 'int'),\n",
       "  [909056, 0, 549722961, 101033, 5441.0238337968785, 9663047.709473047]]]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark-2.3.0 / PySpark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
