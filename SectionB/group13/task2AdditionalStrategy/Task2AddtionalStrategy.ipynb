{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './col_lab/'\n",
    "col_type = []\n",
    "with open(directory+'labels_cur.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        col_type.append((row[0], row[1], row[2], row[3], row[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = []\n",
    "all_trainable = []\n",
    "for val in col_type:\n",
    "    tp = val[2]\n",
    "    all_trainable.append((val[0], val[4], val[2], val[3]))\n",
    "    if tp == 'business_name' or tp == 'school_name' or tp == 'park_playground':\n",
    "        trainable.append((val[0], val[4], val[2], val[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('word_vec.model') == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './col_lab/labels'\n",
    "all_train_files = {}\n",
    "all_name_count = {i[2]:{'count':0, 'files': []} for i in all_trainable}\n",
    "for val in all_trainable:\n",
    "    file_id = val[1]\n",
    "    if len(file_id) == 1:\n",
    "        file_id = '00'+file_id\n",
    "    elif len(file_id) == 2:\n",
    "        file_id = '0'+file_id\n",
    "    filename = val[0]+'_'+file_id\n",
    "    file_name = directory+'/'+filename+'.csv'\n",
    "    if os.path.exists(file_name) == False:\n",
    "        file_name = './col_lab/labels_str_new/'+filename+'.csv'\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)\n",
    "            file = {'name': filename, 'count':0, 'val':[], 'label':[]}\n",
    "            for row in csv_reader:\n",
    "                vals = row[0].strip().replace('-', ' ').split(' ')\n",
    "                file['val'].append(vals)\n",
    "                file['label'].append(row[1])\n",
    "            file['count'] = len(file['val'])\n",
    "            all_name_count[val[2]]['files'].append((filename, file['count']))\n",
    "            all_name_count[val[2]]['count'] += file['count']\n",
    "            all_train_files[filename] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './col_lab/labels'\n",
    "train_files = {}\n",
    "name_count = {'business_name':{'count':0, 'files': []}, 'school_name':{'count':0, 'files': []}, 'park_playground':{'count':0, 'files': []}}\n",
    "for val in trainable:\n",
    "    file_id = val[1]\n",
    "    if len(file_id) == 1:\n",
    "        file_id = '00'+file_id\n",
    "    elif len(file_id) == 2:\n",
    "        file_id = '0'+file_id\n",
    "    filename = val[0]+'_'+file_id\n",
    "    with open(directory+'/'+filename+'.csv') as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(csv_reader)\n",
    "        file = {'name': filename, 'count':0, 'val':[], 'label':[]}\n",
    "        for row in csv_reader:\n",
    "            vals = row[0].strip().replace('-', ' ').split(' ')\n",
    "            if len(vals) >=3:\n",
    "                file['val'].append(vals)\n",
    "                file['label'].append(row[1])\n",
    "        file['count'] = len(file['val'])\n",
    "        name_count[val[2]]['files'].append((filename, file['count']))\n",
    "        name_count[val[2]]['count'] += file['count']\n",
    "        train_files[filename] = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_name': {'count': 17130,\n",
       "  'files': [('2bmr-jdsv_000', 157),\n",
       "   ('2v9c-2k7f_003', 110),\n",
       "   ('43nn-pn8j_008', 11124),\n",
       "   ('ci93-uc8s_046', 623),\n",
       "   ('qcdj-rwhu_097', 345),\n",
       "   ('tg3t-nh4h_106', 2888),\n",
       "   ('w9ak-ipjd_153', 1883)]},\n",
       " 'school_name': {'count': 21332,\n",
       "  'files': [('2xh6-psuq_004', 1683),\n",
       "   ('6je4-4x7e_018', 1603),\n",
       "   ('cznr-hmrv_051', 1382),\n",
       "   ('diks-hcwd_053', 1454),\n",
       "   ('pchn-eaxn_090', 2929),\n",
       "   ('pdpg-nn8i_091', 1452),\n",
       "   ('sybh-s59s_105', 1460),\n",
       "   ('tmr6-dfvn_107', 2934),\n",
       "   ('upwt-zvh3_113', 1509),\n",
       "   ('wks3-66bn_128', 1388),\n",
       "   ('sqcr-6mww_190', 950),\n",
       "   ('hy4q-igkk_194', 1389),\n",
       "   ('sxmw-f24h_195', 1199)]},\n",
       " 'park_playground': {'count': 9957,\n",
       "  'files': [('sxx4-xhzg_103', 192),\n",
       "   ('sxx4-xhzg_103', 192),\n",
       "   ('sxmw-f24h_195', 1199),\n",
       "   ('uzcy-9puk_202', 2149),\n",
       "   ('uzcy-9puk_202', 2149),\n",
       "   ('aiww-p3af_203', 2038),\n",
       "   ('aiww-p3af_203', 2038)]}}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = ['tg3t-nh4h_106', 'pchn-eaxn_090', 'uzcy-9puk_202']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Word2Vec and Doc2Vec and Prepare features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [i[0] for j in name_count for i in name_count[j]['files']]\n",
    "sentences = []\n",
    "for file in files:\n",
    "    sentences += train_files[file]['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48419"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = Word2Vec(sentences, sg=1, size=100, window=5, min_count=1)\n",
    "wv_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08794444,  0.22134978, -0.0092202 ,  0.24054499,  0.2705034 ,\n",
       "       -0.0673551 , -0.30584073, -0.471543  ,  0.35528842, -0.3693265 ,\n",
       "       -0.50038296,  0.21671194, -0.42957076, -0.09745683,  0.14815505,\n",
       "        0.13660587,  0.07366879, -0.04761224,  0.14174868,  0.4221395 ,\n",
       "        0.15434976,  0.19260518, -0.6081785 , -0.41330507, -0.08333189,\n",
       "        0.09689377,  0.3075576 ,  0.2537698 , -0.22530046, -0.16096999,\n",
       "       -0.3317518 , -0.20592462, -0.46064785,  0.48434308, -0.37788475,\n",
       "        0.1692698 , -0.0295064 ,  0.06182968,  0.24920659,  0.00878918,\n",
       "        0.24934027,  0.00285243, -0.08500164,  0.02877139,  0.02364055,\n",
       "       -0.11218129,  0.01444972, -0.24496007,  0.15213022, -0.10469245,\n",
       "       -0.0441895 , -0.12661783,  0.07576437,  0.07547969,  0.18130472,\n",
       "        0.16276176,  0.20064329, -0.25726363,  0.02903674,  0.26573703,\n",
       "       -0.15379214, -0.0283741 , -0.20315857, -0.1791972 , -0.03804828,\n",
       "       -0.48056817, -0.3216531 , -0.28046852,  0.15400589,  0.12825847,\n",
       "       -0.28336814, -0.373313  , -0.05407251,  0.0239609 , -0.4921572 ,\n",
       "       -0.22368678, -0.552307  ,  0.01826983, -0.05051113,  0.07970817,\n",
       "        0.1001362 ,  0.01666663,  0.04705251,  0.10044807,  0.12864631,\n",
       "        0.4406985 , -0.22519872, -0.02683054,  0.27263454, -0.19658943,\n",
       "       -0.16311343,  0.13308318,  0.14102618,  0.03250584,  0.32359675,\n",
       "       -0.08714054,  0.1019142 , -0.26015633,  0.2221584 , -0.00970868],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_model.wv['LLC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(sentences)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_model = Doc2Vec(documents, vector_size=100, dbow_words=1, window=2, min_count=1)\n",
    "dv_model.save(\"doc2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02432786,  0.00671296,  0.01756264,  0.00315118, -0.00920516,\n",
       "       -0.0046181 , -0.01185251, -0.00885352,  0.01463391, -0.01515639,\n",
       "       -0.0156415 ,  0.01903179, -0.00299502, -0.00206756,  0.01076518,\n",
       "        0.00421982,  0.00037046,  0.00551941,  0.00562842,  0.01746982,\n",
       "        0.00861378, -0.00765877, -0.03054351, -0.01446205, -0.0056932 ,\n",
       "        0.02271719,  0.02139705,  0.00877519, -0.01864341,  0.0212835 ,\n",
       "        0.002142  , -0.03463773,  0.01375672,  0.00631976, -0.00902638,\n",
       "       -0.00669712,  0.02104242,  0.02200629, -0.01583948,  0.01031362,\n",
       "       -0.00611978, -0.01115874,  0.00275569, -0.01603691,  0.00903394,\n",
       "       -0.01203439, -0.02247518,  0.01777174,  0.02019343,  0.00753158,\n",
       "       -0.0030833 ,  0.00123608, -0.01432449, -0.02428816, -0.0009323 ,\n",
       "        0.01942965,  0.0106469 ,  0.00055742, -0.00638309,  0.01983718,\n",
       "       -0.00490953, -0.01879386,  0.02069506, -0.00517643,  0.00409388,\n",
       "       -0.00145344, -0.01980117,  0.00301836, -0.00889048,  0.01032758,\n",
       "        0.01011822,  0.009094  , -0.00748543, -0.00061291, -0.04234008,\n",
       "       -0.01597317, -0.01897941,  0.00939096, -0.01883567,  0.02120038,\n",
       "       -0.00118584,  0.01022401,  0.00462486, -0.00510033, -0.00924641,\n",
       "        0.02236878, -0.00326544,  0.01091727,  0.00434011,  0.00301748,\n",
       "       -0.00757354, -0.01934627,  0.00193528,  0.01238461,  0.00851548,\n",
       "       -0.01144674, -0.0263553 , -0.00924644,  0.01024992, -0.01558298],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv_model.infer_vector(['Chinese', 'Restaurants'])\n",
    "# try:\n",
    "#     wv_model.wv['1111111111']\n",
    "# except:\n",
    "#     print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed items: 5000\n",
      "Processed items: 10000\n",
      "Processed items: 15000\n",
      "Processed items: 20000\n",
      "Processed items: 25000\n",
      "Processed items: 30000\n",
      "Processed items: 35000\n",
      "Processed items: 40000\n"
     ]
    }
   ],
   "source": [
    "feature_label = train_files\n",
    "count = 0\n",
    "for key in feature_label:\n",
    "    feature_label[key]['features'] = []\n",
    "    feature_label[key]['d2v'] = []\n",
    "    w2vs = None\n",
    "    for val in feature_label[key]['val']:\n",
    "        count += 1\n",
    "        if count % 5000 == 0:\n",
    "            print(\"Processed items:\", count)\n",
    "        for word in val:\n",
    "            if w2vs is None:\n",
    "                w2vs = wv_model.wv[word]\n",
    "            else:\n",
    "                w2vs = np.vstack((w2vs, wv_model.wv[word]))\n",
    "        w2v = np.mean(w2vs, axis=0)\n",
    "        d2v = dv_model.infer_vector(val)\n",
    "        feature  = list(w2v)+list(d2v)\n",
    "        feature_label[key]['d2v'].append(d2v)\n",
    "        feature_label[key]['features'].append(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 23 27\n"
     ]
    }
   ],
   "source": [
    "train_names = ['tg3t-nh4h_106', 'pchn-eaxn_090', 'uzcy-9puk_202']\n",
    "test_names = [i for i in files if i not in train_names]\n",
    "print(len(train_names), len(test_names), len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7966 7966\n",
      "(7966, 200) (7966, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for name in train_names:\n",
    "    X_train += train_files[name]['features']\n",
    "    y_train += train_files[name]['label']\n",
    "print(len(X_train), len(y_train))\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_true_pred_labels = {}\n",
    "for name in test_names:\n",
    "    X_test = np.array(train_files[name]['features'])\n",
    "    y_test = np.array(train_files[name]['label'])\n",
    "    y_test = y_test.reshape(y_test.shape[0],1)\n",
    "#     print(X_test.shape, y_test.shape)\n",
    "    y_pred = clf.predict(X_test)\n",
    "#     print(y_pred.shape)\n",
    "    uniq_true, count_true = np.unique(y_test, return_counts=True)\n",
    "    uniq_pred, count_pred = np.unique(y_pred, return_counts=True)\n",
    "    dict_true_pred_labels[name] = {}\n",
    "    dict_true_pred_labels[name]['true'] = {i:j for i in uniq_true for j in count_true}\n",
    "    dict_true_pred_labels[name]['pred'] = {i:j for i,j in zip(uniq_pred, count_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2bmr-jdsv_000': {'true': {'business_name': 157},\n",
       "  'pred': {'school_name': 157}},\n",
       " '2v9c-2k7f_003': {'true': {'business_name': 110},\n",
       "  'pred': {'school_name': 110}},\n",
       " '43nn-pn8j_008': {'true': {'business_name': 11124},\n",
       "  'pred': {'business_name': 9935, 'school_name': 1189}},\n",
       " 'ci93-uc8s_046': {'true': {'business_name': 623},\n",
       "  'pred': {'business_name': 623}},\n",
       " 'qcdj-rwhu_097': {'true': {'business_name': 345},\n",
       "  'pred': {'business_name': 280, 'school_name': 65}},\n",
       " 'w9ak-ipjd_153': {'true': {'business_name': 1883},\n",
       "  'pred': {'business_name': 1844, 'school_name': 39}},\n",
       " '2xh6-psuq_004': {'true': {'school_name': 1683},\n",
       "  'pred': {'business_name': 13, 'school_name': 1670}},\n",
       " '6je4-4x7e_018': {'true': {'school_name': 1603},\n",
       "  'pred': {'park_playground': 1600, 'school_name': 3}},\n",
       " 'cznr-hmrv_051': {'true': {'school_name': 1382},\n",
       "  'pred': {'park_playground': 1382}},\n",
       " 'diks-hcwd_053': {'true': {'school_name': 1454},\n",
       "  'pred': {'park_playground': 1454}},\n",
       " 'pdpg-nn8i_091': {'true': {'school_name': 1452},\n",
       "  'pred': {'park_playground': 1137, 'school_name': 315}},\n",
       " 'sybh-s59s_105': {'true': {'school_name': 1460},\n",
       "  'pred': {'park_playground': 1169, 'school_name': 291}},\n",
       " 'tmr6-dfvn_107': {'true': {'school_name': 2934},\n",
       "  'pred': {'school_name': 2934}},\n",
       " 'upwt-zvh3_113': {'true': {'school_name': 1509},\n",
       "  'pred': {'park_playground': 1506, 'school_name': 3}},\n",
       " 'wks3-66bn_128': {'true': {'school_name': 1388},\n",
       "  'pred': {'school_name': 1388}},\n",
       " 'sqcr-6mww_190': {'true': {'school_name': 950},\n",
       "  'pred': {'park_playground': 950}},\n",
       " 'hy4q-igkk_194': {'true': {'school_name': 1389},\n",
       "  'pred': {'park_playground': 1389}},\n",
       " 'sxmw-f24h_195': {'true': {'park_playground': 1199},\n",
       "  'pred': {'park_playground': 1199}},\n",
       " 'sxx4-xhzg_103': {'true': {'park_playground': 192},\n",
       "  'pred': {'park_playground': 192}},\n",
       " 'aiww-p3af_203': {'true': {'park_playground': 2038},\n",
       "  'pred': {'park_playground': 2038}}}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_true_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_name': {'count': 0, 'files': []},\n",
       " 'person_name': {'count': 0, 'files': []},\n",
       " 'school_name': {'count': 0, 'files': []},\n",
       " 'area_of_study': {'count': 0, 'files': []},\n",
       " 'borough': {'count': 0, 'files': []},\n",
       " 'building_classification': {'count': 0, 'files': []},\n",
       " 'city_agency': {'count': 0, 'files': []},\n",
       " 'school_level': {'count': 0, 'files': []},\n",
       " 'website': {'count': 0, 'files': []},\n",
       " 'neighborhood': {'count': 0, 'files': []},\n",
       " 'subject_in_school': {'count': 0, 'files': []},\n",
       " 'phone_number': {'count': 0, 'files': []},\n",
       " 'lat_lon_cord': {'count': 0, 'files': []},\n",
       " 'address': {'count': 0, 'files': []},\n",
       " 'street_name': {'count': 0, 'files': []},\n",
       " 'Bulding classification': {'count': 0, 'files': []},\n",
       " 'color': {'count': 0, 'files': []},\n",
       " 'car_make': {'count': 0, 'files': []},\n",
       " 'park_playground': {'count': 0, 'files': []},\n",
       " 'zip_code': {'count': 0, 'files': []},\n",
       " 'location_type': {'count': 0, 'files': []},\n",
       " 'vehicle_type': {'count': 0, 'files': []},\n",
       " 'address_number': {'count': 0, 'files': []}}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{i[2]:{'count':0, 'files': []} for i in all_trainable}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 42058,\n",
       " 'files': [('n84m-kx4j_086', 35),\n",
       "  ('vr8p-8shw_121', 1854),\n",
       "  ('pq5i-thsu_156', 6637),\n",
       "  ('bjuu-44hx_172', 6318),\n",
       "  ('pvqr-7yc4_188', 1630),\n",
       "  ('jt7v-77mi_211', 6870),\n",
       "  ('kiv2-tbus_217', 6030),\n",
       "  ('2bnn-yakx_219', 5701),\n",
       "  ('c284-tqph_222', 6983)]}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_name_count['car_make']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './col_lab/labels'\n",
    "car_make = []\n",
    "for val in ['n84m-kx4j_086', 'vr8p-8shw_121', 'pq5i-thsu_156', 'bjuu-44hx_172', 'pvqr-7yc4_188', \\\n",
    "            'jt7v-77mi_211', 'kiv2-tbus_217', '2bnn-yakx_219', 'c284-tqph_222']:\n",
    "    file_name = directory+'/'+val+'.csv'\n",
    "    if os.path.exists(file_name) == False:\n",
    "        file_name = './col_lab/labels_str_new/'+filename\n",
    "    if os.path.exists(file_name):\n",
    "        with open(file_name) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            next(csv_reader)\n",
    "            for row in csv_reader:\n",
    "                car_make.append(row[0].strip().lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_car_make = set(car_make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_table=pd.read_csv('task2Data/as69-ew8f.tsv', sep='\\t', header=0)\n",
    "tsv_columns=tsv_table.columns\n",
    "truck_make = tsv_table['TruckMake'].to_list()\n",
    "semantic_type = {'car_make':0, 'car_model':0, 'license_plate':0}\n",
    "other = []\n",
    "for i in truck_make:\n",
    "    i_split = i.lower().split(\" \")\n",
    "    if len(i_split) == 2 and i_split[0] in ['ram', 'ford']:\n",
    "        semantic_type['car_model'] += 1\n",
    "    elif i_split[0] == 'ag16439':\n",
    "        semantic_type['license_plate'] += 1\n",
    "    else:\n",
    "        semantic_type['car_make'] += 1\n",
    "        other.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car_make': 118816, 'car_model': 719, 'license_plate': 1}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_table=pd.read_csv('task2Data/ph7v-u5f3.tsv', sep='\\t', header=0)\n",
    "tsv_columns=tsv_table.columns\n",
    "truck_make = tsv_table['TOP VEHICLE MODELS - 5'].dropna().to_list()\n",
    "semantic_type = {'car_make':0, 'car_model':0, 'license_plate':0}\n",
    "other = []\n",
    "for i in truck_make:\n",
    "    if i.strip().lower() in set_car_make:\n",
    "        semantic_type['car_make'] += 1\n",
    "    else:\n",
    "        semantic_type['car_model'] += 1\n",
    "        other.append(i)\n",
    "#     i_split = i.lower().split(\" \")\n",
    "#     if len(i_split) == 2 and i_split[0] in ['ram', 'ford']:\n",
    "#         semantic_type['car_model'] += 1\n",
    "#     elif i_split[0] == 'ag16439':\n",
    "#         semantic_type['license_plate'] += 1\n",
    "#     else:\n",
    "#         semantic_type['car_make'] += 1\n",
    "#         other.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car_make': 1, 'car_model': 646, 'license_plate': 0}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
